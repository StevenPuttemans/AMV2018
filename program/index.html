<!DOCTYPE html>
<html lang="en-us">

<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="The first workshop on Advanced Machine Vision for real-life and industrially relevant applications.">

<base href="https://stevenputtemans.github.io/AMV2018/">
<title>


     Program 

</title>
<link rel="canonical" href="https://stevenputtemans.github.io/AMV2018/program/">






<script type="text/javascript" src="/AMV2018/js/jquery-3.3.1.min.js"></script>


<link rel="stylesheet" href="/AMV2018/css/font-awesome.min.css">
<link rel="stylesheet" href="/AMV2018/css/nunito_sans.css">


    <link rel="stylesheet" href="/AMV2018/css/light-style.css">






<link rel="shortcut icon" href="/AMV2018/img/fav.ico">



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-120928140-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>





</head>


<body>
<div class="section" id="top">
    

    <div class="container hero  fade-in one ">
        
        <h1 class="bold-title is-1">Program</h1>
    </div>
    

    
    <div class="section  fade-in two ">
        <div class="container">
            
            <hr>
<nav class="nav nav-center">
    <span id="nav-toggle" class="nav-toggle"  onclick="document.getElementById('nav-menu').classList.toggle('is-active');">
      <span></span>
      <span></span>
      <span></span>
    </span>
    <div id="nav-menu" class="nav-left nav-menu">
      <span class="nav-item">
        <a href="/AMV2018/">Main</a>
      </span>
      <span class="nav-item">
        <a href="/AMV2018/about">About</a>
      </span>
      
      
      <span class="nav-item">
        <a href="/AMV2018/contact">Contact</a>
      </span>
    
      <span class="nav-item">
        <a href="https://stevenputtemans.github.io/AMV2018/index.xml"><i class="fa fa-rss"></i></a>
      </span>
    
    </div>
</nav>
<hr>

        </div>
        

        <div class="container markdown  fade-in two  top-pad">
            
            
            

<p><em><strong>The program itself is still under construction and will be made publicly available in due time.</strong></em></p>

<p>We can already confirm the following invited speakers:</p>

<h3 id="1-yongsheng-gao">1) Yongsheng Gao</h3>

<p><img align="right" src="img/profile_yongsheng.jpg"></p>

<h4 id="vision-perception-for-automation-in-agriculture-and-aquaculture">Vision Perception for Automation in Agriculture and Aquaculture</h4>

<p>Environmental informatics studies new knowledge, technologies and devices for automation in agriculture and aquaculture, early detection of pest and plant disease, automatic species identification, plant phenomics, better water resource management, land environment monitoring, costal environment monitoring, marine life surveillance, etc. In this talk, he will introduce some of their work on automation in agriculture and aquaculture, faster grading and packing, species and cultivar identification, pest and disease recognition at Environmental Informatics @ Griffith, including recognition without detection, large image database retrieval (speed vs accuracy), and pose difference.</p>

<h4 id="biography">Biography</h4>

<p>Professor Yongsheng Gao is the Director of Australian Research Council (ARC) Research Hub for Driving Farming Productivity and Disease Prevention, the founding Leader of the Environmental Informatics flagship group and the Director of Computer Vision and Image Processing Research Lab at Griffith University. He served as the project leader of Biosecurity Group, National ICT Australia (ARC Centre of Excellence) from 2009 to 2011. He is a current member of College of Experts (Panel Member), Australian Research Council. As a Chief Investigator, he has been working on projects in Australia, Singapore, Germany, and China in the areas of smart farming, biosecurity, face recognition, biometrics, image retrieval, computer vision, pattern recognition, environmental informatics, and medical imaging. He was also employed as a consultant by Panasonic Singapore Laboratories Pte Ltd working on the face recognition standard in MPEG-7. His research are reported in the media in Australia and Singapore, including The Australian, The Courier Mail, The Sydney Morning Herald, and The Straits Times (Singapore).</p>

<h3 id="2-moussa-reda-mansour">2) Moussa Reda Mansour</h3>

<p><img align="right" src="img/profile_moussa.jpg"></p>

<h4 id="detecting-anomalies-in-the-wild-the-challenges-and-the-future">Detecting Anomalies in the Wild: The Challenges and the Future.</h4>

<p>If anomaly detection is just about learning the normal and detecting abnormal activities, why is it so hard to employ in the real world? While it is straightforward for us to spot the unusual or discover strange activities, this task is quite challenging for computers. The meaning of what constitutes an anomaly changes for every environment, with weather, traditions and social behaviour playing important roles. This brings us a mystery to solve, which is something that we love and it is the heart of anomaly detection.  However, unlike mystery/thriller movies, in anomaly detection, the problem to solve is not always clear, and we may not even know what we are trying to solve. This leads us to the main question to be discussed in this talk: what are the main challenges in implementing anomaly detection techniques that can employed in the wild, and what can we expect for the future of such algorithms?</p>

<h4 id="biography-1">Biography</h4>

<p>Dr. Moussa Reda Mansour is the Research &amp; Development Lead at iCetana, a world leader in AI assisted video anomaly detection. He received his Ph.D degree in electrical and computer engineering from the University of Sao Paulo, Brazil, in 2013.  In the same year, he started a research fellow position at Institute of Mathematical and Computer Sciences (ICMC-USP), in which he led projects in machine learning, computer vision, data visualisation and graph theory. Later, as a research fellow at the University of Illinois at Urbana-Champaign, Dr. Reda Mansour worked with data visualisation and machine learning applied in large social networks with textual information. Currently, his main areas of research are Computer Vision, Unsupervised Learning, Deep Learning and Dynamical Systems applied in Learning Tasks.</p>

        </div>
        

        <div class="disqus">
            
        </div>

        <div class="container has-text-centered top-pad">
            <hr>
            <a href="#top">
                <i class="fa fa-arrow-up"></i>
            </a>
            <hr>
        </div>

        <div class="section" id="footer">
    <div class="container has-text-centered">
    
        AMV2018 workshop website made with the <a href="https://themes.gohugo.io/hugo-theme-introduction/">Introduction</a> theme for <a href="https://gohugo.io/">Hugo</a>.
    
    </div>
</div>

    </div>
    
</div>



<script>
    $('a[href^="https:\/\/stevenputtemans.github.io\/AMV2018\/program\/#"]').click(function (e) {
        e.preventDefault();
        var target = this.hash;
        $('html, body').animate({
            scrollTop: $(target).offset().top
        }, 500);
        return false;
    })
</script>

</body>
