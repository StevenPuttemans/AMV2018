<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta name="generator" content="Hugo 0.51" />
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="The first workshop on Advanced Machine Vision for real-life and industrially relevant applications.">

<base href="https://stevenputtemans.github.io/AMV2018/">
<title>


     1st workshop on Advanced Machine Vision for Real-life and Industrially Relevant Applications  

</title>
<link rel="canonical" href="https://stevenputtemans.github.io/AMV2018/">






<script type="text/javascript" src="/AMV2018/js/jquery-3.3.1.min.js"></script>


<link rel="stylesheet" href="/AMV2018/css/font-awesome.min.css">
<link rel="stylesheet" href="/AMV2018/css/nunito_sans.css">


    <link rel="stylesheet" href="/AMV2018/css/light-style.css">






<link rel="shortcut icon" href="/AMV2018/img/fav.ico">



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-120928140-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




  <link href="https://stevenputtemans.github.io/AMV2018/index.xml" rel="alternate" type="application/rss+xml" title="1st workshop on Advanced Machine Vision for Real-life and Industrially Relevant Applications " />


</head>

<body>

<div id="top"> 

<div class="hero is-medium">

    
    <div class="hero-body" style="background-image: url('img/background.jpg'); background-size: 100% 100%;;">
        <div class="container has-text-centered">
            
            <h1 class="bold-title fade-in one" style="color: #ffffff; text-shadow: 1px 1px #000000;">
                AMV 2018
            </h1>
            <h3 class="subtitle is-3 fade-in two" style="color: #ffffff; text-shadow: 1px 1px #000000;">
                1st International Workshop on Advanced Machine Vision for Real-life and Industrially Relevant Applications
            </h3>
	    <h3 class="subtitle is-4 fade-in three" style="color: #ffffff; text-shadow: 1px 1px #000000;">
			Monday, 3rd of December
            </h3>
	    <h3 class="subtitle is-4 fade-in three" style="color: #ffffff; text-shadow: 1px 1px #000000;">
                A workshop in conjunction with ACCV 2018 in Perth, Australia.
            </h3>
            
            
            <div class=" fade-in four">
                <div class="social-icons">
    
</div>
            </div>
            
        </div>
    </div> 
    
    <div class="hero-foot fade-in four">
    <hr>
    <nav class="nav-center">
        <a class="nav-item" href="#home">Home</a>
	<a class="nav-item" href="#cfp">Call For Papers</a>
	<a class="nav-item" href="#submission">Submission</a>
	<a class="nav-item" href="#dates">Important Dates</a>
	<a class="nav-item" href="#people">People</a>
	<a class="nav-item" href="#program">Program</a>
    </nav>
    <hr>
    </div>
</div>


<div class="section no-padding fade-in four">


<div class="section" id="home">
    <div class="container">
    <h2 class="title is-2 has-text-centered">Home</h2>
            <div class="column markdown">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                            <p>We are proud to present the 1st International Workshop on <strong>A</strong>dvanced <strong>M</strong>achine <strong>V</strong>ision for Real-life and Industrially Relevant Applications (<strong>AMV2018</strong>). This workshop is in conjunction with <a href="http://accv2018.net/">ACCV2018</a>, Perth, Australia and is scheduled on <strong>Monday the 3rd of December 2018</strong> <em>(all-day workshop)</em>.</p>

<p>A large variety of industrially oriented applications (e.g. quality control, pick and place) have in the past decades been successfully implemented throughout a wide range of industries. These implementations are characterized by very controlled surroundings and objects (e.g. CAD models of objects available, controlled lighting). <strong><em>Advanced Machine Vision</em></strong> refers to computer vision - based systems where such assumptions do not hold, for example, when handling biological objects as seen in the food-production industry or when operating outdoors. With recent advancements in sensing and processing power, the potential for further automation in industry based on computer vision is clearly present. Furthermore, the exploding domain of computer vision algorithms (e.g. deep learning) provides dozens of new opportunities. However, there is in general a major gap between the topics in focus at major international computer vision conferences and the actual industrial needs. More often approaches are hardly transferable into practical and robust solutions for industrial challenges. The ambition of this workshop is to close this gap, by bringing together both academics and practitioners from the field.</p>

<p>The workshop will take place at the conference venue: The <a href="https://www.pcec.com.au/">Perth Convention and Exhibition Centre</a> (PCEC), 21 Mounts Bay Road, Perth, Australia.</p>

                    
                
                    
                
                    
                
                    
                
                    
                
            </div>
    </div>
<div class="container has-text-centered top-pad"><a href="#top"><i class="fa fa-arrow-up"></i></a></div>
</div>

<hr>


<div class="section" id="cfp">
    <div class="container">
    <h2 class="title is-2 has-text-centered">Call For Papers</h2>
            <div class="column markdown">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                            <p><em>Please find a pdf version of this call for papers by clicking <a href="https://stevenputtemans.github.io/AMV2018/cfp_AMV2018.pdf">here</a></em></p>

<p>The ambition of this full-day <strong>AMV2018</strong> workshop is to bring together practitioners and researchers from different disciplines related to Advanced Machine Vision to share ideas and methods on current and future use of computer vision algorithms in real-life and industrially relevant systems. This field raises the need of applied research that focusses on the technology
transfer from academics towards practitioners, yielding several challenges like top-notch accuracies, real-time processing, minimal training data, minimal manual input, user-friendly
interfaces, &hellip;</p>

<p>To this end we welcome contributions with a strong focus on (but not limited to) the following
topics within Advanced Machine Vision:</p>

<ul>
<li><p>Sensing</p>

<ul>
<li>Camera selection</li>
<li>Camera setup</li>
<li>Different wavelengths</li>
<li>Multi-modal data</li>
</ul></li>

<li><p>Improving robustness of algorithms</p>

<ul>
<li>Real-time performance</li>
<li>Non-controlled illumination</li>
<li>Non-trivial intra object variability</li>
<li>Top-notch accuracies</li>
</ul></li>

<li><p>Removing or reducing the need of training data</p>

<ul>
<li>Data augmentation</li>
<li>Artificial data</li>
</ul></li>

<li><p>Processing power and memory requirements</p></li>

<li><p>Obtaining training data and ground truth annotations</p></li>

<li><p>Lab testing versus inline testing</p></li>

<li><p>Transfer learning towards new applicational domains</p></li>

<li><p>Deep learning for advanced machine vision</p></li>

<li><p>Quality assessment of non-trivial objects</p></li>

<li><p>Real-life and industrially relevant applications</p></li>
</ul>

<p>The workshop has a best paper award of <strong>$1000</strong> sponsored by <a href="https://icetana.com/">iCetana</a>. On top of that there will be a special issue of the <a href="https://link.springer.com/journal/138">Machine Vision and Applications</a> journal following the workshop. This special issue will be for both extended workshop papers as well as an open call.</p>

                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </div>
    </div>
<div class="container has-text-centered top-pad"><a href="#top"><i class="fa fa-arrow-up"></i></a></div>
</div>

<hr>


<div class="section" id="submission">
    <div class="container">
    <h2 class="title is-2 has-text-centered">Submission</h2>
            <div class="column markdown">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                            <p>Authors are encouraged to submit high-quality, original (i.e. not been previously published or accepted for publication in substantially similar form in any peer-reviewed venue including journal, conference or workshop) research.</p>

<p>The paper template is identical to the main ACCV2018 conference:</p>

<ul>
<li>LaTeX Templates (zip): <a href="http://accv2018.net/wp-content/uploads/accv2018kit.zip">accv2018kit.zip</a></li>
<li>Example submission paper with detailed instructions: <a href="http://accv2018.net/wp-content/uploads/accv2018submission.pdf">accv2018submission.pdf</a></li>
</ul>

<p>Papers are limited to 14 pages, excluding references. The review process is double blind. <strong>Papers that are not blind, or do not use the template, or have more than 14 pages (excluding references) will be rejected without review.</strong> For details concerning the blind review we refer to the example submission paper linked above. All workshop submissions follow the policies of ACCV 2018 (found <a href="http://accv2018.net/call-for-papers/#callforpapers">here</a>).</p>

<p>Submissions are handled through the CMT submission website: <a href="https://cmt3.research.microsoft.com/AMV2018">CLICK HERE FOR SUBMISSION</a></p>

<p>Authors are requested to submit their paper in a <strong>single PDF file</strong> <em>(maximum file size 20MB)</em>. Submission of supplementary material is optional (up to 100MB). Accepted file formats for supplementary material are: PDF, PNG, JPG, GIF, ZIP, MP4, WMV, MPEG or AVI.</p>

<p>All accepted workshop papers will be published as workshop post-proceedings in the <a href="https://www.springer.com/gp/computer-science/lncs">Lecture Notes in Computer Science (LNCS)</a> by <a href="https://www.springer.com/gp">Springer</a>, after the actual meeting, in order to exclude no-show papers from publication. On top of that, questions and feedback raised at the workshop can be used on top of the review comments to improve the camera-ready submission.</p>

<p>On top of that there will be a <strong>special issue</strong> of the <a href="https://link.springer.com/journal/138"><strong>Machine Vision and Applications</strong></a> journal following the workshop. This special issue will be for both extended workshop papers as well as an open call.</p>

<p>For questions/remarks regarding the submission e-mail: <a href="mailto:amv2018workshop@gmail.com">amv2018workshop@gmail.com</a>.</p>

                    
                
            </div>
    </div>
<div class="container has-text-centered top-pad"><a href="#top"><i class="fa fa-arrow-up"></i></a></div>
</div>

<hr>


<div class="section" id="dates">
    <div class="container">
    <h2 class="title is-2 has-text-centered">Important Dates</h2>
            <div class="column markdown">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                            <ul>
<li><strong><del>EXTENDED paper submission deadline: 30th of September 2018 (11:59 CEST)</del></strong></li>
<li><del>Notification of acceptance + reviews available: 26th of October 2018</del></li>
<li>Workshop date: Monday 3th of December 2018 - all day</li>
<li>Post-proceedings camera-ready deadline: TBD</li>
</ul>

                    
                
                    
                
                    
                
                    
                
            </div>
    </div>
<div class="container has-text-centered top-pad"><a href="#top"><i class="fa fa-arrow-up"></i></a></div>
</div>

<hr>


<div class="section" id="people">
    <div class="container">
    <h2 class="title is-2 has-text-centered">People</h2>
            <div class="column markdown">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                            <p><h3 class="has-text-centered">Workshop Organizers</h3> <br /></p>

<div class="columns">
    <div class="column has-text-centered">
      <img class="img-responsive avatar" src="img/profile_tmo.jpg" alt="My profile picture.">
    </div>
    <div class="column markdown">
        <b>Thomas B. Moeslund</b><br />
    Professor<br />
    Visual Analysis of People Lab<br >
    Aalborg University<br />
    Denmark<br /><br />
    Website: <a href="http://thbm.blog.aau.dk/">click here</a>
    </div>
    <div class="column has-text-centered">
      <img class="img-responsive avatar" src="img/profile_rga.jpg" alt="My profile picture.">
    </div>
    <div class="column markdown">
        <b>Rikke Gade</b><br />
    Assistant Professor<br >
    Visual Analysis of People Lab<br >
    Aalborg University<br />
    Denmark<br /><br />
    Website: <a href="http://rgade.blog.aau.dk/">click here</a>
    </div>
</div>

<div class="columns">
    <div class="column has-text-centered">
      <img class="img-responsive avatar" src="img/profile_tgo.jpg" alt="My profile picture.">
    </div>
    <div class="column markdown">
        <b>Toon Goedeme</b><br />
    Professor<br />
    EAVISE Research Group<br >
    KU Leuven<br />
    Belgium<br /><br />
    Website: <a href="https://iiw.kuleuven.be/onderzoek/eavise/people/00041334">click here</a>
    </div>
    <div class="column has-text-centered">
      <img class="img-responsive avatar" src="img/profile_spu.jpg" alt="My profile picture.">
    </div>
    <div class="column markdown">
        <b>Steven Puttemans</b><br />
    Post-doctoral researcher<br />
    EAVISE Research Group<br >
    KU Leuven<br />
    Belgium<br /><br />
    Website: <a href="http://stevenputtemans.github.io">click here</a>
    </div>
</div>

<div class="columns">
    <div class="column has-text-centered">
      <img class="img-responsive avatar" src="img/profile_ami.jpg" alt="My profile picture.">
    </div>
    <div class="column markdown">
        <b>Ajmal Mian</b><br />
    Professor<br />
    School of Physics, Mathematics & Computing, The University of Western Australia<br />
    Australia<br /><br />
    Website: <a href="http://www.web.uwa.edu.au/person/ajmal.mian">click here</a>
    </div>
    <div class="column has-text-centered">
      
    </div>
    <div class="column markdown">
        
    </div>
</div>

<p><h3 class="has-text-centered">Program Committee</h3> <br /></p>

<p><b>Benhur Ortiz Jaramillo</b>, UGent <br />
<b>Bjorn Barz</b>, Friedrich-Schiller-University Jena<br />
<b>Brian Booth</b>, University of Antwerp<br />
<b>Christian Reimers</b>, Friedrich-Schiller-University Jena<br />
<b>Clemens Brust</b>, Friedrich-Schiller-University Jena<br />
<b>Dries Hulens</b>, KU Leuven<br />
<b>Enrique Sanchez Lozano</b>, University of Nottingham<br />
<b>Feng Chen</b>, University of Nottingham<br />
<b>Isma Hadji</b>, York University<br />
<b>Jie Chen</b>, University of Oulu<br />
<b>Joachim Denzler</b>, Friedrich-Schiller-University Jena<br />
<b>Kristof Van Beeck</b>, KU Leuven<br />
<b>Lei Shi</b>, University of Antwerp<br />
<b>Ljubomir Jovanov</b>, UGent<br />
<b>Martin Kampel</b>, Vienna University of Technology<br />
<b>Miguel Bordallo Lopez</b>, University of Oulu<br />
<b>Mohammad Malekzadeh</b>, Queen Mary University of London<br />
<b>Nikola Banic</b>, University of Zagreb<br />
<b>Roxane Licandro</b>, Medical University of Vienna, TU Wien<br />
<b>Sebastian Zambanini</b>, TU Wien<br />
<b>Steve Vanlanduit</b>, University of Antwerp<br />
<b>Tamas Suveges</b>, University of Dundee<br />
<b>Thorsten Falk</b>, University Of Freiburg<br />
<b>Timothy Callemein</b>, KU Leuven<br />
<b>Tomislav Petkovic</b>, University of Zagreb<br />
<b>Ulrich Schwanecke</b>, Hoghschule RheinMain<br />
<b>Violeta Teodora Trifunov</b>, Friedrich-Schiller-University Jena<br />
<b>Wiebe Van Ranst</b>, KU Leuven<br />
<b>Xiaohua Huang</b>, University of Oulu<br />
<b>Xiatian Zhu</b>, Queen Mary University of London<br />
<b>Xin Liu</b>, University of Oulu<br /></p>

<p>The organizing committee would like to thank all members of the program committee for the work they invest in assuring that our AMV2018 workshop achieves a high-quality standard!</p>

                    
                
                    
                
                    
                
            </div>
    </div>
<div class="container has-text-centered top-pad"><a href="#top"><i class="fa fa-arrow-up"></i></a></div>
</div>

<hr>


<div class="section" id="program">
    <div class="container">
    <h2 class="title is-2 has-text-centered">Program</h2>
            <div class="column markdown">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                            

<h2 id="invited-speakers">Invited speakers</h2>

<h3 id="1-yongsheng-gao">1) Yongsheng Gao</h3>

<p><img align="right" src="img/profile_yongsheng.jpg"></p>

<h4 id="vision-perception-for-automation-in-agriculture-and-aquaculture">Vision Perception for Automation in Agriculture and Aquaculture</h4>

<p>Environmental informatics studies new knowledge, technologies and devices for automation in agriculture and aquaculture, early detection of pest and plant disease, automatic species identification, plant phenomics, better water resource management, land environment monitoring, costal environment monitoring, marine life surveillance, etc. In this talk, he will introduce some of their work on automation in agriculture and aquaculture, faster grading and packing, species and cultivar identification, pest and disease recognition at Environmental Informatics @ Griffith, including recognition without detection, large image database retrieval (speed vs accuracy), and pose difference.</p>

<h4 id="biography">Biography</h4>

<p>Professor Yongsheng Gao is the Director of Australian Research Council (ARC) Research Hub for Driving Farming Productivity and Disease Prevention, the founding Leader of the Environmental Informatics flagship group and the Director of Computer Vision and Image Processing Research Lab at Griffith University. He served as the project leader of Biosecurity Group, National ICT Australia (ARC Centre of Excellence) from 2009 to 2011. He is a current member of College of Experts (Panel Member), Australian Research Council. As a Chief Investigator, he has been working on projects in Australia, Singapore, Germany, and China in the areas of smart farming, biosecurity, face recognition, biometrics, image retrieval, computer vision, pattern recognition, environmental informatics, and medical imaging. He was also employed as a consultant by Panasonic Singapore Laboratories Pte Ltd working on the face recognition standard in MPEG-7. His research are reported in the media in Australia and Singapore, including The Australian, The Courier Mail, The Sydney Morning Herald, and The Straits Times (Singapore).</p>

<h3 id="2-faisal-shafait">2) Faisal Shafait</h3>

<p><img align="right" src="img/profile_faisal.jpg"></p>

<h4 id="packagex-a-journey-from-deep-learning-to-hand-crafting">PackageX: A journey from Deep Learning to Hand Crafting</h4>

<p>Document Image Analysis and Recognition has served as a proven test bed for machine learning and computer vision research. Deep learning architectures like Convolutional Neural Networks and Long Short-Term Memory Networks made their mark on various document recognition problems before they got the attention of the broader research community. In this talk, I will present our work on reading package labels and how that evolved into PackageX, the last yard AI solution for managing incoming deliveries which is currently deployed across four continents. I will illustrate our journey that started with deep learning at its core but soon started heading towards classical pattern recognition techniques. In doing so, I will highlight various practical aspects that are often ignored in deep learning research but are crucial for deploying large scale systems in the real-world. I will conclude by providing some recommendations for design considerations when developing practical computer vision and machine learning systems.</p>

<h4 id="biography-1">Biography</h4>

<p>Dr. Faisal Shafait is currently working as the Director of Deep Learning Laboratory at the National Center of Artificial Intelligence, Islamabad, Pakistan as well as a Professor at School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan. Previously, he was an Assistant Research Professor at the School of Computer Science and Software Engineering at The University of Western Australia in Perth, Australia; a Senior Researcher at the German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; and a Visiting Researcher at Google Inc., Mountain View, California. He received his PhD with the highest distinction in computer engineering from TU Kaiserslautern, Germany in 2008. His research interests include machine learning and pattern recognition with a special emphasis on applications in document image analysis. He has co-authored over 150 publications in international peer-reviewed conferences and journals in this area. He is serving as the Founding President of Pakistani Pattern Recognition Society, which is IAPR&rsquo;s official chapter in Pakistan. Besides academics, Faisal has also been actively involved in a number of startup and spin-off companies and is currently working as CTO of VisionX Technologies, LLC.</p>

<h2 id="tentative-program">Tentative program</h2>

<table>
<thead>
<tr>
<th align="left">Time</th>
<th align="left">What</th>
<th align="left">Who</th>
<th align="left">Title</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">08:30</td>
<td align="left">Conference Registration Open</td>
<td align="left">- - - -</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">09:00</td>
<td align="left">Welcome</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">09:15</td>
<td align="left">Keynote</td>
<td align="left">YongSheng Gao</td>
<td align="left">Vision Perception for Automation in Agriculture and Aquaculture</td>
</tr>

<tr>
<td align="left">10:00</td>
<td align="left">Coffee Break</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">10:30</td>
<td align="left">Oral Paper 1</td>
<td align="left">Sina Shafaei</td>
<td align="left">Integration of Driver Behavior into Emotion Recognition Systems: A Preliminary Study on Steering Wheel and Vehicle Acceleration</td>
</tr>

<tr>
<td align="left">10:55</td>
<td align="left">Oral Paper 2</td>
<td align="left">Feras Almasri</td>
<td align="left">Multimodal Sensor Fusion In Single Thermal image Super-Resolution</td>
</tr>

<tr>
<td align="left">11:20</td>
<td align="left">Oral Paper 3</td>
<td align="left">Robert Frohlich</td>
<td align="left">Simultaneous Multi-View Relative Pose Estimation and 3D Reconstruction from Planar Regions</td>
</tr>

<tr>
<td align="left">11:45</td>
<td align="left">Oral Paper 4</td>
<td align="left">Quan Kong</td>
<td align="left">Multimodal Deep Neural Networks based Ensemble Learning for X-ray Object Recognition</td>
</tr>

<tr>
<td align="left">12:10</td>
<td align="left">Lunch Break</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">13:35</td>
<td align="left">Keynote</td>
<td align="left">Faisal Shafait</td>
<td align="left">PackageX: A journey from Deep Learning to Hand Crafting</td>
</tr>

<tr>
<td align="left">14:20</td>
<td align="left">Oral Paper 5</td>
<td align="left">Christian Bartz</td>
<td align="left">LoANs: Weakly Supervised Object Detection with Localizer Assessor Networks</td>
</tr>

<tr>
<td align="left">14:45</td>
<td align="left">Oral Paper 6</td>
<td align="left">Yasir Jan</td>
<td align="left">WNet: Joint multiple head detection and head pose estimation from a spectator crowd image</td>
</tr>

<tr>
<td align="left">15:10</td>
<td align="left">Coffee break + Poster session</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">17:10</td>
<td align="left">Best paper award</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">17:20</td>
<td align="left">Closing remarks</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>
</tbody>
</table>

<p>Papers presented solely during poster session:</p>

<ul>
<li>Reaching behind Specular Highlights by Registration of Two Images of Broiler Viscera</li>
<li>Unconstrained Iris Segmentation using Convolutional Neural Networks</li>
<li>Visual Siamese Clustering for Cosmetic Product Recommendation</li>
<li>PCA-RECT: An Energy-efficient Object Detection Approach for Event Cameras</li>
<li>Anomaly Detection Using GANs for Visual Inspection in Noisy Training Data</li>
<li>Prediction based deep autoencoding model for anomaly detection</li>
<li>Markerless Augmented Advertising for Sports Videos</li>
</ul>

<p>All oral presentations will also have a poster available to foster further discussion on the topics presented.</p>

                    
                
                    
                
            </div>
    </div>
<div class="container has-text-centered top-pad"><a href="#top"><i class="fa fa-arrow-up"></i></a></div>
</div>

<hr>


<div class="section" id="footer">
    <div class="container has-text-centered">
    
        AMV2018 workshop website made with the <a href="https://themes.gohugo.io/hugo-theme-introduction/">Introduction</a> theme for <a href="https://gohugo.io/">Hugo</a>.
    
    </div>
</div>


</div>



<script>
$('a[href^="#"]').click(function(e) {
    e.preventDefault();
    var target = this.hash;
    $('html, body').animate({
    scrollTop: $(target).offset().top
    }, 500);
    return false;
})
</script>

</body>
